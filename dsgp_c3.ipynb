{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgrdtGOrqApo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier, VotingClassifier\n",
        ")\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from google.colab import files\n",
        "\n",
        "# Step 1: Upload the dataset\n",
        "print(\"Upload your dataset:\")\n",
        "uploaded = files.upload()  # Prompt for file upload\n",
        "filename = list(uploaded.keys())[0]\n",
        "\n",
        "# Step 2: Load the dataset\n",
        "data = pd.read_csv(filename)\n",
        "print(\"First few rows of the dataset:\")\n",
        "display(data.head())\n",
        "\n",
        "# Step 3: Check for the target variable\n",
        "target_column = 'PCOS (Y/N)'\n",
        "if target_column not in data.columns:\n",
        "    raise ValueError(f\"Target column '{target_column}' not found in dataset.\")\n",
        "\n",
        "# Step 4: Handle missing values\n",
        "numeric_data = data.select_dtypes(include=['float64', 'int64'])  # Select only numeric columns\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "data_imputed = imputer.fit_transform(numeric_data)\n",
        "\n",
        "# Step 5: Standardize the data\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data_imputed)\n",
        "\n",
        "# Step 6: Perform PCA\n",
        "pca = PCA()\n",
        "pca_result = pca.fit_transform(data_scaled)\n",
        "\n",
        "# Step 7: Visualize Explained Variance\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "cumulative_variance = np.cumsum(explained_variance)\n",
        "\n",
        "# Scree Plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(1, len(explained_variance) + 1), explained_variance, marker='o', label='Individual Variance')\n",
        "plt.title('Scree Plot')\n",
        "plt.xlabel('Principal Components')\n",
        "plt.ylabel('Explained Variance Ratio')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Cumulative Variance Plot\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', color='orange', label='Cumulative Variance')\n",
        "plt.axhline(y=0.9, color='r', linestyle='--', label='90% Threshold')\n",
        "plt.title('Cumulative Explained Variance')\n",
        "plt.xlabel('Principal Components')\n",
        "plt.ylabel('Cumulative Variance Ratio')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Step 8: Find number of components explaining ~90% variance\n",
        "num_components_90 = np.argmax(cumulative_variance >= 0.9) + 1\n",
        "print(f\"Number of components to explain ~90% variance: {num_components_90}\")\n",
        "\n",
        "# Step 9: Reduce data using selected components\n",
        "pca_df = pd.DataFrame(pca_result[:, :num_components_90], columns=[f'PC{i+1}' for i in range(num_components_90)])\n",
        "pca_df[target_column] = data[target_column].values  # Add the target column back to the PCA data\n",
        "\n",
        "# Step 10: EDA with PCA\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.scatterplot(x='PC1', y='PC2', hue=target_column, data=pca_df)\n",
        "plt.title('Scatter Plot of First Two Principal Components')\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Step 11: Split the data for classification\n",
        "X = pca_df.drop(columns=[target_column])  # Features\n",
        "y = pca_df[target_column]  # Target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 12: Define and evaluate models\n",
        "# Define a dictionary of individual models\n",
        "base_models = {\n",
        "    \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=1000),\n",
        "    \"Support Vector Machine (Linear Kernel)\": SVC(kernel='linear', random_state=42),\n",
        "    \"Support Vector Machine (RBF Kernel)\": SVC(kernel='rbf', random_state=42),\n",
        "    \"Random Forest Classifier\": RandomForestClassifier(random_state=42),\n",
        "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(random_state=42),\n",
        "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
        "    \"Decision Tree Classifier\": DecisionTreeClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "# Define ensemble models\n",
        "ensemble_models = {\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
        "    \"AdaBoost\": AdaBoostClassifier(base_estimator=DecisionTreeClassifier(random_state=42), random_state=42),\n",
        "    \"Bagging (Decision Tree)\": BaggingClassifier(base_estimator=DecisionTreeClassifier(random_state=42), random_state=42),\n",
        "    \"Voting Classifier (Hard)\": VotingClassifier(estimators=[\n",
        "        (\"Logistic Regression\", LogisticRegression(random_state=42, max_iter=1000)),\n",
        "        (\"SVM\", SVC(kernel='rbf', probability=True, random_state=42)),\n",
        "        (\"Decision Tree\", DecisionTreeClassifier(random_state=42))\n",
        "    ], voting='hard'),\n",
        "    \"Voting Classifier (Soft)\": VotingClassifier(estimators=[\n",
        "        (\"Logistic Regression\", LogisticRegression(random_state=42, max_iter=1000)),\n",
        "        (\"SVM\", SVC(kernel='rbf', probability=True, random_state=42)),\n",
        "        (\"Decision Tree\", DecisionTreeClassifier(random_state=42))\n",
        "    ], voting='soft')\n",
        "}\n",
        "\n",
        "# Combine all models\n",
        "all_models = {**base_models, **ensemble_models}\n",
        "\n",
        "# Dictionary to store results\n",
        "results = {}\n",
        "\n",
        "print(\"\\n--- Evaluating All Models (Base + Ensemble) ---\\n\")\n",
        "for model_name, model in all_models.items():\n",
        "    print(f\"Training and evaluating: {model_name}\")\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    results[model_name] = accuracy\n",
        "\n",
        "    # Print performance metrics\n",
        "    print(f\"Accuracy for {model_name}: {accuracy:.4f}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Step 13: Visualize Model Performance\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.bar(results.keys(), results.values(), color='skyblue')\n",
        "plt.title('Model Accuracy Comparison (Including Ensemble Models)', fontsize=16)\n",
        "plt.ylabel('Accuracy', fontsize=14)\n",
        "plt.xlabel('Models', fontsize=14)\n",
        "plt.xticks(rotation=45, fontsize=12)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print the best model\n",
        "best_model_name = max(results, key=results.get)\n",
        "print(f\"The best performing model is: {best_model_name} with accuracy: {results[best_model_name]:.4f}\")\n",
        "\n",
        "# Step 14: Save PCA results with target\n",
        "pca_df.to_csv('pca_transformed_data_with_target.csv', index=False)\n",
        "print(\"PCA results with target saved as 'pca_transformed_data_with_target.csv'\")\n"
      ]
    }
  ]
}